{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 3090\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "model_name = \"VIT B16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Adjust size for ViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set the paths for the datasets\n",
    "base_folder = \"../datasets/Vision_data\"\n",
    "train_folder = os.path.join(base_folder, \"train\")\n",
    "test_folder = os.path.join(base_folder, \"test\")\n",
    "validation_folder = os.path.join(base_folder, \"validation\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ImageFolder(root=train_folder, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_folder, transform=transform)\n",
    "validation_dataset = ImageFolder(root=validation_folder, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batchsize = 32\n",
    "numworkers = 6\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=numworkers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False, num_workers=numworkers)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batchsize, shuffle=False, num_workers=numworkers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def train_one_epoch(model, data_loader, criterion, optimizer, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Update the tqdm description to show current epoch\n",
    "    for inputs, labels in tqdm(data_loader, desc=f\"Epoch {epoch}/{num_epochs} - Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device, epoch, num_epochs, phase='Validation'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Update the tqdm description to show current epoch and phase (Validation or Testing)\n",
    "    for inputs, labels in tqdm(data_loader, desc=f\"Epoch {epoch}/{num_epochs} - {phase}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "            \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                           Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, model_path):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, model_path):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if val_loss < self.val_loss_min:\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} to {val_loss:.6f}). Saving model ...')\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'in_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mvit_b_16(weights\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mViT_B_16_Weights\u001b[38;5;241m.\u001b[39mIMAGENET1K_V1)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheads\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Check if the model has the attribute 'heads'\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     in_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_features\u001b[49m  \u001b[38;5;66;03m# Get the number of input features from the current head\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features, num_classes)  \u001b[38;5;66;03m# Replace it with a new Linear layer with the correct number of output classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'in_features'"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(num_classes)\n",
    "model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "if hasattr(model, 'heads'):  # Check if the model has the attribute 'heads'\n",
    "    in_features = model.heads.in_features  # Get the number of input features from the current head\n",
    "    model.heads = nn.Linear(in_features, num_classes)  # Replace it with a new Linear layer with the correct number of output classes\n",
    "else:\n",
    "    print(\"The model does not have a 'heads' attribute. Please check the model architecture.\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.001)\n",
    "model_path = \"../output/vitb16/ViT_B_16_best.pth\"  # Adjust as needed\n",
    "\n",
    "# Initialize TensorBoard\n",
    "writer = SummaryWriter('../output/vitb16_experiment')  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store metrics\n",
    "columns = pd.DataFrame(columns=[\n",
    "    'Epoch', 'Training Loss', 'Validation Loss', 'Test Loss',\n",
    "    'Training Accuracy', 'Validation Accuracy', 'Test Accuracy',\n",
    "    'Training Precision', 'Training Recall', 'Training F1-Score',\n",
    "    'Validation Precision', 'Validation Recall', 'Validation F1-Score',\n",
    "    'Test Precision', 'Test Recall', 'Test F1-Score'\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy, train_prec, train_rec, train_f1 = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch, num_epochs)\n",
    "    \n",
    "    val_loss, val_accuracy, val_prec, val_rec, val_f1 = evaluate(\n",
    "        model, validation_loader, criterion, device, epoch, num_epochs)\n",
    "\n",
    "    # Early stopping and scheduler\n",
    "    early_stopping(val_loss, model, model_path)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    scheduler.step()\n",
    "\n",
    "    # Collect data for DataFrame\n",
    "    df_metrics = df_metrics.append({\n",
    "        'Epoch': epoch + 1,\n",
    "        'Training Loss': train_loss, 'Validation Loss': val_loss, 'Test Loss': None,\n",
    "        'Training Accuracy': train_accuracy, 'Validation Accuracy': val_accuracy, 'Test Accuracy': None,\n",
    "        'Training Precision': train_prec, 'Training Recall': train_rec, 'Training F1-Score': train_f1,\n",
    "        'Validation Precision': val_prec, 'Validation Recall': val_rec, 'Validation F1-Score': val_f1,\n",
    "        'Test Precision': None, 'Test Recall': None, 'Test F1-Score': None\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "test_loss, test_accuracy, test_prec, test_rec, test_f1 = evaluate(\n",
    "    model, test_loader, criterion, device, epoch, num_epochs, phase='Testing')\n",
    "\n",
    "# Update DataFrame with test results\n",
    "df_metrics.loc[df_metrics['Epoch'] == num_epochs, ['Test Loss', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-Score']] = \\\n",
    "    [test_loss, test_accuracy, test_prec, test_rec, test_f1]\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"ViT_B_16_training_results_{timestamp}.csv\"\n",
    "df_metrics.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_metrics['Epoch'], df_metrics['Training Loss'], label='Training Loss')\n",
    "plt.plot(df_metrics['Epoch'], df_metrics['Validation Loss'], label='Validation Loss')\n",
    "plt.plot(df_metrics['Epoch'], df_metrics['Test Loss'], label='Test Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_metrics['Epoch'], df_metrics['Training Accuracy'], label='Training Accuracy')\n",
    "plt.plot(df_metrics['Epoch'], df_metrics['Validation Accuracy'], label='Validation Accuracy')\n",
    "plt.plot(df_metrics['Epoch'], df_metrics['Test Accuracy'], label='Test Accuracy', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

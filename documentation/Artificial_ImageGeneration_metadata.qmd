---
title: "Image Document"
bibliography: references.bib
format:
  pdf:
    documentclass: scrartcl
    classoption: [sfdefaults=false]
    papersize: letter
    cite-method: natbib
    keep_tex: true
    include-in-header: preamble.tex
    pdf-engine: xelatex
    geometry:
      - top=1.25in
      - left=1.0in
      - right=1.0in
      - bottom=1.0in
      - heightrounded
author:
  - name: "Nakul R. Padalkar"
    affiliation: "Georgetown University"
    email: "nakul.padalkar@georgetown.edu"
abstract: |
  This is the abstract of your document, where you summarize the contents.
keywords:
  - keyword1
  - keyword2
  - keyword3
crossref:
  fig-title: '**Figure**'
  fig-labels: '**arabic**'
  title-delim: "**.**"
  tbl-title: '**Table**'
  tbl-labels: '**arabic**'
execute:
  echo: false
  output: true
  message: false
  warning: false
latex-auto-install	: true
---

# Introduction

This document contains sample images from each folder from the vision dataset. The vision dataset is a collection of images from a specific camera source. There are 11 manufacturers and 35 devices. Apple, Samsung, and Huawei are the top three manufacturers. The table below shows the number of devices per manufacturer [@bennabhaktula2022source].

```{r tablechunk,tab.cap="Device Count per Manufacturer", echo=FALSE, message=FALSE, warning=FALSE}

#| include: true
library(kableExtra)
library(readr)
options(readr.show_col_types = FALSE)

# Read the CSV file
df <- read_csv("../datasets/vision/manufacturer_device_list.csv")

# Create the table with kable and kableExtra
kbl(df, booktabs=T, escape = FALSE)%>%
  kable_styling(position = "center", latex_options = c("hold_position")) %>%
  row_spec(0,bold=TRUE)%>%
  column_spec(1, width = "2.5cm") %>%
  column_spec(2, width = "1.5cm") %>%
  column_spec(3, width = "8.0cm", extra_css = "word-wrap: break-word;")

```


```{r figurechunk, fig.cap="Device Count per Manufacturer", fig.align='center', fig.height=4.75, fig.width=6, out.width="0.8\\linewidth", echo=FALSE, message=FALSE, warning=FALSE, fig.pos="H"}
library(ggplot2)

df$`Count` <- as.numeric(df$`Count`)

# Define the color for the bars
bar_color <- "#336699"

# Create the ggplot
# Create the ggplot
p <- ggplot(df, aes(x = Manufacturer, y = `Count`, fill = Manufacturer)) +
  geom_bar(stat = "identity", color = "#003366", fill = "#336699") +
  geom_text(aes(label = `Count`), vjust = -0.3) +
  theme_minimal() +
  theme(
    # panel.border = element_rect(color = "black", fill = NA, size = 0.25),
    # panel.grid.major = element_line(color = "#a7a7a7", linetype = "dashed", size=0.5),
    # panel.grid.minor = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(),
    plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
  ) +
  labs(title = "Device Count per Manufacturer",
       x = "Manufacturer",
       y = "Count")

# Print the plot
print(p)
```

# Image Counts Per class

The images are mainly divided into two types: 1) Flat surface Images, referred to as *Flat* and 2) Generic Images, referred to as *Nat*. Flat images are mostly landscape images of flat surfaces like skies, walls, and roads. Generic images are images of objects, people, and animals. Here is a general structure of the dataset. 

1. Flat Images (Flat)
2. General Images (Nat)
   1. General Images Shared through WhatsApp (NatWA)
   2. General Images Shared through Facebook (NatFB)
      1. High Quality Images (NatFBH)
      2. Low Quality Images (NatFBL)

## True Image Counts

The following figure shows the number of images in each class and subclass. Based on this distribution, we can generate an approximate distribution of the images needed for the AI-generated images. 

```{r figurechunk2, fig.cap="Image Count per Class", fig.align='center', fig.height=10.0, fig.width=8.0, out.width="0.95\\linewidth", echo=FALSE,fig.dpi=300, message=FALSE, warning=FALSE, fig.pos="H"}
library(tidyverse)
library(ggplot2)

# Assuming the CSV file is named 'manufacturer_device_list.csv' and located in the current working directory
df <- read_csv('../datasets/vision/dynamic_class_folders_counts.csv')

# Reshape the data to long format for images and videos
df_long <- df %>%
  pivot_longer(
    cols = starts_with("images_") | starts_with("videos_"),
    names_to = "Type",
    values_to = "Count"
  ) %>%
  mutate(
    Category = if_else(str_detect(Type, "^images_"), "Images", "Videos"),
    Type = str_remove(Type, "^images_|^videos_")
  )

# Create a function to plot grouped bar charts
plot_grouped_bars <- function(data, category_filter) {
  data %>%
    filter(Category == category_filter) %>%
    mutate(Type = factor(Type, levels = unique(Type))) %>%
    ggplot(aes(x = Classes, y = Count, fill = Type)) +
    geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
    theme_minimal() +
    labs(title = paste(category_filter, "Counts per Class"), x = "Class", y = "Count") +
    theme(
          # panel.border = element_rect(color = "black", fill = NA, size = 0.25),
          panel.grid.major = element_line(color = "#a7a7a7", linetype = "dashed", size=0.5),
          panel.grid.minor = element_blank(),
          axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position='bottom',
          legend.title = element_blank()
      ) +
    scale_fill_brewer(palette = "Set1") +
    guides(fill = guide_legend(reverse = TRUE)) +
    coord_flip()
}

# Plot images grouped bar chart
plot_images <- plot_grouped_bars(df_long, "Images");plot_images

# Plot videos grouped bar chart
plot_videos <- plot_grouped_bars(df_long, "Videos");plot_videos

# Save the plots as PDF in landscape format
ggsave("images_grouped_bars.pdf", plot_images, device = "pdf", width = 11, height = 8.5, units = "in")
ggsave("videos_grouped_bars.pdf", plot_videos, device = "pdf", width = 11, height = 8.5, units = "in")
```

## AI Image Counts

Based on the counts above, the following table shows the number of images needed for each class and subclass. The AI-generated images will be used to augment the dataset. If possible, we will need the granularity of the images per class. The current estimate is to have 10% of the images per class to be AI-generated. Image samples are available in `output\data_characteristics` folder on Github.


```{r figurechunk3, fig.cap="Image Count per Class", fig.align='center', fig.height=8.0, fig.width=7.5, out.width="0.95\\linewidth", echo=FALSE,fig.dpi=300, message=FALSE, warning=FALSE, fig.pos="H"}

library(ggplot2)
library(dplyr)
library(readr)

df <- read_csv('../datasets/vision/ai_class_folders_counts.csv')
df <- df[1:35,1:6]
# Reshape the data to long format for images
df_long <- df %>%
  pivot_longer(
    cols = starts_with("images_"),
    names_to = "Category",
    values_to = "Count"
  ) %>%
  mutate(Category = str_remove(Category, "images_"))

# Create the ggplot for images
ggplot(df_long, aes(x = Classes, y = Count, fill = Category)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  theme_minimal() +
  theme(
          # panel.border = element_rect(color = "black", fill = NA, size = 0.25),
          panel.grid.major = element_line(color = "#c7c7c7", linetype = "dashed", size=0.5),
          panel.grid.minor = element_blank(),
          axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position='bottom',
          legend.title = element_blank()
      ) +
  labs(title = "Image Counts per Class", x = "Class", y = "Count") +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.title = element_blank()) +
  coord_flip()  # Flipping the coordinates for landscape orientation

```


```{r tablechunk2, echo=FALSE, message=FALSE, warning=FALSE}
#| tbl-cap: "AI Images per Class"
#| tbl-cap-location: top
#| tbl-align: center
library(kableExtra)
library(readr)
options(readr.show_col_types = FALSE)
df <- read_csv('../datasets/vision/ai_class_folders_counts.csv')
df <- df[,1:7]

colnames(df) <- c('Classes', 'flat','nat','natFBH','natFBL','natWA', 'Total')

# Create the table with kable and kableExtra
kable_output <- df %>%
  kbl(booktabs = TRUE, latex_options = c("hold_position")) %>%
  row_spec(0, bold = TRUE) %>%
  row_spec(35, hline_after = TRUE) %>%
  row_spec(36, bold = TRUE, color = '#336699', hline_after = TRUE)

# Define the colors for each manufacturer from the Visibone softer palette
colors <- c("Apple" = "#B58AA5", "Samsung" = "#BDCFBD", "Huawei" = "#D6DFFF")

# Apply conditional formatting to rows based on 'Classes' content
for (manufacturer in names(colors)) {
  highlight_rows <- which(grepl(manufacturer, df$Classes))
  kable_output <- kable_output %>%
    row_spec(highlight_rows, background = colors[manufacturer])
}

# Print the table
kable_output

```

```{r tablechunk3, echo=FALSE, message=FALSE, warning=FALSE}
#| tbl-cap: "AI Images per Class for Apple"
#| tbl-cap-location: top
#| tbl-align: center
# Filter and sort the dataframe
df <- read_csv('../output/device_subset_AI_Apple.csv')

# Create the table with kable and kableExtra
kbl(df, booktabs=T, escape = TRUE)%>%
  kable_styling(position = "center", latex_options = c("hold_position")) %>%
  row_spec(0,bold=TRUE)%>%
  row_spec(13, hline_after = TRUE) %>%
  row_spec(14, bold = TRUE, color = '#336699', hline_after = TRUE)
```

```{r tablechunk4, echo=FALSE, message=FALSE, warning=FALSE}
#| tbl-cap: "AI Images per Class for Huawei"
#| tbl-cap-location: top
#| tbl-align: center
# Filter and sort the dataframe
df <- read_csv('../output/device_subset_AI_Huawei.csv')

# Create the table with kable and kableExtra
kbl(df, booktabs=T, escape = TRUE)%>%
  kable_styling(position = "center", latex_options = c("hold_position")) %>%
  row_spec(0,bold=TRUE)%>%
  row_spec(5, hline_after = TRUE) %>%
  row_spec(6, bold = TRUE, color = '#336699', hline_after = TRUE)
```

```{r tablechunk5, echo=FALSE, message=FALSE, warning=FALSE}
#| tbl-cap: "AI Images per Class for Samsung"
#| tbl-cap-location: top
#| tbl-align: center
# Filter and sort the dataframe
df <- read_csv('../output/device_subset_AI_Samsung.csv')
# Create the table with kable and kableExtra

kbl(df, booktabs=T, escape = TRUE)%>%
  kable_styling(position = "center", latex_options = c("hold_position")) %>%
  row_spec(0,bold=TRUE)%>%
  row_spec(8, hline_after = TRUE) %>%
  row_spec(9, bold = TRUE, color = '#336699', hline_after = TRUE)
```

# References


